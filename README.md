# Desafio de Data Engineer - EMD
Pipeline de Dados em Tempo Real para Monitoramento de Ã”nibus BRT

## Sobre o Projeto
Este projeto foi desenvolvido como parte do desafio tÃ©cnico para a posiÃ§Ã£o de Engenheiro(a) de Dados no EscritÃ³rio de Dados do Rio de Janeiro. O objetivo Ã© demonstrar a capacidade de construir uma pipeline de dados robusta e escalÃ¡vel.

## DescriÃ§Ã£o do Desafio
O projeto consiste em desenvolver uma pipeline ETL que:
- Captura dados em tempo real da API de GPS dos Ã´nibus BRT
- Estrutura e processa os dados coletados
- Armazena os dados em diferentes camadas (CSV e PostgreSQL)
- Transforma os dados utilizando dbt para anÃ¡lises

## Arquitetura da SoluÃ§Ã£o
A soluÃ§Ã£o foi implementada como um sistema distribuÃ­do utilizando containers Docker e orquestrada pelo Prefect.

### Componentes Principais

#### Infraestrutura
- **Docker**: ContainerizaÃ§Ã£o e isolamento dos serviÃ§os
- **Prefect**: OrquestraÃ§Ã£o e monitoramento dos workflows
- **PostgreSQL**: Armazenamento dos dados processados
- **Redis**: Cache e gerenciamento de estado

#### ServiÃ§os do Prefect
![Prefect_Architecture](imgs/prefect_architecture.png)

- **UI**: Dashboard para monitoramento e gestÃ£o
- **Apollo**: API principal do servidor
- **PostgreSQL**: Armazenamento de metadados
- **Hasura**: API GraphQL
- **Towel**: UtilitÃ¡rios de manutenÃ§Ã£o
  - Scheduler
  - Zombie Killer
  - Lazarus

### Pipeline de Dados

#### 1. IngestÃ£o (Camada Bronze)
- Coleta de dados da API BRT a cada minuto
- Dados incluem: ID do veÃ­culo, coordenadas GPS, velocidade e timestamp
- Armazenamento em arquivos CSV (rotaÃ§Ã£o a cada 10 minutos)
- Carregamento para tabela PostgreSQL `bronze.brt_data`

#### 2. TransformaÃ§Ã£o (Camada Gold)
- Processamento via dbt a cada 10 minutos
- CriaÃ§Ã£o de materialized view `gold.vw_brt_last_info`
- Campos selecionados: ID do Ã´nibus, posiÃ§Ã£o atual e velocidade

## Requisitos
- Docker e Docker Compose
- Conta no Redis Cloud (para cache)

## InstalaÃ§Ã£o e ExecuÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/NicolasEvilasio/emd-desafio-data-eng.git
```

2. Configure as variÃ¡veis de ambiente:
Crie um arquivo `.env` na raiz do projeto com as seguintes configuraÃ§Ãµes:

```env
# BRT DATABASE
DB_USER=postgres
DB_PASSWORD=postgres
DB_DATABASE=brt_db
DB_PORT=5432
DB_EXTERNAL_PORT=5433
DB_HOST=brt_postgres

# PREFECT DATABASE
PREFECT_DB_USER=prefect
PREFECT_DB_PASSWORD=test-password
PREFECT_DB_DATABASE=prefect_server
PREFECT_DB_PORT=5434

# REDIS (Insira suas credenciais do Redis Cloud)
REDIS_HOST=
REDIS_PORT=
REDIS_USERNAME=
REDIS_PASSWORD=
```

3. Inicie os serviÃ§os:
```bash
docker-compose --profile prefect --profile agent --profile pipeline up
```

## Monitoramento e AnÃ¡lise

### Prefect UI
- Acesse o dashboard em: http://localhost:8080
- Monitore flows e tasks em tempo real
![Prefect UI](imgs/prefect_ui.png)

### AnÃ¡lise de Dados
- Notebooks de exemplo disponÃ­veis na pasta `analysis`  
- Visualize os dados processados na view `gold.vw_brt_last_info`  
![vw_brt_last_info](imgs/vw_brt_last_info.png)

## Estrutura do Projeto
```
.ğŸ“‚
â”œâ”€â”€ ğŸ“‚analysis/          # Notebooks para anÃ¡lise
â”œâ”€â”€ ğŸ“‚data/              # CSV coletados atravÃ©s da API BRT
â”œâ”€â”€ ğŸ“‚dbt_brt/           # Projeto dbt para transformaÃ§Ã£o dos dados
â”œâ”€â”€ ğŸ“‚imgs/              # Imagens do README
â”œâ”€â”€ ğŸ“‚pipelines/         # CÃ³digo fonte das pipelines
â”œâ”€â”€ ğŸ“œ.env
â”œâ”€â”€ ğŸ“œ.gitignore
â”œâ”€â”€ ğŸ“œdocker-compose.yml
â”œâ”€â”€ ğŸ³dockerfile
â”œâ”€â”€ ğŸ“œentrypoint.sh
â”œâ”€â”€ ğŸ“œpoetry.lock
â”œâ”€â”€ âš™ï¸pyproject.toml
â”œâ”€â”€ ğŸ“œREADME.md
```

## ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, sinta-se Ã  vontade para submeter um Pull Request.